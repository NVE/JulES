{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009d8280",
   "metadata": {},
   "source": [
    "# Prototype JulES v1\n",
    "\n",
    "Check out the ReadMe page on Github for a description of JulES. This is a demo of the prototype implementation of JulES in a stepwise manner. Here are some of the most important steps: \n",
    "- Load the TuLiPa and JulES code on parallel processors so that we can run scenarios and subsystems in parallel\n",
    "- Decide on simulation and scenario parameters\n",
    "- First time step in the simulation and initializing\n",
    "    - Load datasets for the European power system/market.\n",
    "    - Initialize and run price prognosis models\n",
    "    - Do scenario modelling for the stochastic subsystem models\n",
    "    - Initialize and run the stochastic subsystem models\n",
    "    - Initialize and run the market clearing problem\n",
    "    - Collect results\n",
    "- Simulate the next time steps\n",
    "    - Run price prognosis models, scenario modelling, stochastic subsystem models, market clearing and collect results for each time step\n",
    "- Postprocess, store and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0bc3e",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ffdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg;\n",
    "# Pkg.update(\"TuLiPa\") # uncomment to update TuLiPa to latest version\n",
    "# Pkg.develop(path=joinpath(dirname(dirname(pwd())),\"TuLiPa\")); Pkg.status() # go to development version\n",
    "# Pkg.undo(); Pkg.status() # go back to main package version\n",
    "# Pkg.add(url=\"https://github.com/NVE/TuLiPa.git\") # alternative go back to latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf4aa8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using DataFrames, Plots, Statistics, JSON, Distributed, Clustering\n",
    "plotlyjs(); # uncomment for interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c3161",
   "metadata": {},
   "source": [
    "### Prepare parallell processing - import code on all cores\n",
    "The problem is simulated on 31 2.20 GHz processors running in parallel. TODO: Test on faster processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "const numcores = 31\n",
    "\n",
    "if nprocs() < numcores\n",
    "    addprocs(numcores - nprocs())\n",
    "end\n",
    "\n",
    "@show nprocs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2448075",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using TuLiPa, Dates\n",
    "# @everywhere include(joinpath(dirname(dirname(dirname(pwd()))),\"jgrc/TuLiPa/src/TuLiPa.jl\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246922ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere include(joinpath(dirname(pwd()),\"src/JulES.jl\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf98105",
   "metadata": {},
   "source": [
    "### Starting point and scenario settings\n",
    "- Series simulation 30 years with moving horizons and two day time steps. Starting from model year 2025 and weather scenario 1981.\n",
    "- 30 possible weather scenarios (1981-2010) that can be used to consider uncertainty (we use scenario modelling later)\n",
    "- Scenarios are phased in after two days\n",
    "    - First two days have perfect information from simulation/main scenario\n",
    "    - Next 5 weeks combines simulation/main scenario and scenario X. Smooth transition.\n",
    "    - After 5 weeks the simulation/main scenario is fully phased out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datayearstart = 2023\n",
    "scenarioyear = 1995 # 1991 - 2010 hovedinput\n",
    "weekstart = 46\n",
    "\n",
    "scenarioyearstart = 1991\n",
    "scenarioyearstop = 2021\n",
    "\n",
    "totalscen = 30 # scenarios to consider uncertainty for\n",
    "simulationyears = 3\n",
    "\n",
    "# Standard time for market clearing - perfect information so simple time type\n",
    "datatime = getisoyearstart(datayearstart) + Week(weekstart-1)\n",
    "tnormal = PrognosisTime(datatime, datatime, getisoyearstart(scenarioyear) + Week(weekstart-1))\n",
    "\n",
    "# Phasein settings\n",
    "phaseinoffsetdays = 2 # also simulation step length\n",
    "phaseinoffset = Millisecond(Day(phaseinoffsetdays)) # phase in straight away from second stage scenarios\n",
    "phaseindelta = Millisecond(Week(5)) # Phase in the second stage scenario over 5 weeks\n",
    "phaseinsteps = 5 # Phase in second stage scenario in 5 steps\n",
    "\n",
    "# Make scenario times for all uncertainty scenarios. List of tuples with tnormal, tphasein and scenarionumber\n",
    "totalscentimes = []\n",
    "for scen in 1:totalscen\n",
    "    scentnormal = PrognosisTime(datatime, datatime, getisoyearstart(scenarioyear + scen - 1) + Week(weekstart-1))\n",
    "    scentphasein = PhaseinPrognosisTime(datatime, datatime, getisoyearstart(scenarioyear) + Week(weekstart-1), getisoyearstart(scenarioyear + scen - 1) + Week(weekstart-1), phaseinoffset, phaseindelta, phaseinsteps);\n",
    "\n",
    "    push!(totalscentimes, (scentnormal, scentphasein, scen))\n",
    "end\n",
    "\n",
    "# How many time steps to run the simulation for\n",
    "steps = 9;\n",
    "# steps = Int(ceil((getisoyearstart(datayearstart + simulationyears) - getisoyearstart(datayearstart)).value/phaseinoffset.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6cec37",
   "metadata": {},
   "source": [
    "### Price prognosis models uses NVEs Europe dataset for the TheMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e769ab",
   "metadata": {},
   "source": [
    "This is a simplified version of the dataset NVE uses for its long-term power market analyses (for example https://www.nve.no/energi/analyser-og-statistikk/langsiktig-kraftmarkedsanalyse/). The dataset consist of:\n",
    "- Detailed thermal units, aggregated hydro (Res, RoR, PHS), inelastic wind and solar, demands (inelastic with cutoff / load shedding price), storages (hydro and battery), transmission (ATC) and price areas (endogenous and exogenous). \n",
    "- Levels in 2021, 2025, 2030, 2040 and 2050 (e.g. commodity price levels, installed production/transmission/storage capacities etc.)\n",
    "- Profiles (e.g. availability profiles for transmission or production units, commodity price profiles, weather scenario profiles 1981-2010 for demand, solar, wind and inflow etc.)\n",
    "\n",
    "We cannot publish the full dataset, but many of the profiles for wind, solar, hydro and demand can be downloaded from https://www.nve.no/energi/analyser-og-statistikk/vaerdatasett-for-kraftsystemmodellene/.\n",
    "\n",
    "#### NB! \n",
    "- In this demo we use the model year 2025. This scenario was made a couple of years ago and results should be considered outdated. A lot has happened in the power market since then. In addition the dataset is simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8db8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sti_dataset = joinpath(JSON.parsefile(joinpath(pwd(), \"jules_config.json\"), use_mmap=false)[1], \"prognosemodell\", \"prognoser\", \"static_input\")\n",
    "sti_dataset1 = joinpath(JSON.parsefile(joinpath(pwd(), \"jules_config.json\"), use_mmap=false)[1], \"prognosemodell\", \"prognoser\", \"Uke_$weekstart\", \"input\")\n",
    "\n",
    "exd = JSON.parsefile(joinpath(sti_dataset1, \"exogenprices_prognose1.json\"))\n",
    "exogen = getelements(exd, sti_dataset1);\n",
    "\n",
    "add = JSON.parsefile(joinpath(sti_dataset, \"aggdetd2.json\"))\n",
    "aggdetd = getelements(add, sti_dataset);\n",
    "\n",
    "ipad = JSON.parsefile(joinpath(sti_dataset1, \"tilsigsprognoseragg$scenarioyear.json\"))\n",
    "agginflow = getelements(ipad, sti_dataset1);\n",
    "\n",
    "thd = JSON.parsefile(joinpath(sti_dataset, \"termisk1.json\"))\n",
    "thermal = getelements(thd, sti_dataset);\n",
    "\n",
    "wsd = JSON.parsefile(joinpath(sti_dataset, \"vindsol.json\"))\n",
    "windsol = getelements(wsd, sti_dataset);\n",
    "\n",
    "trd = JSON.parsefile(joinpath(sti_dataset1, \"nett.json\"))\n",
    "transm = getelements(trd);\n",
    "\n",
    "cod = JSON.parsefile(joinpath(sti_dataset, \"forbruk5.json\"))\n",
    "cons = getelements(cod, sti_dataset);\n",
    "\n",
    "fpd = JSON.parsefile(joinpath(sti_dataset1, \"brenselspriser.json\"))\n",
    "fuel = getelements(fpd, sti_dataset1);\n",
    "\n",
    "nud = JSON.parsefile(joinpath(sti_dataset1, \"nuclear.json\"))\n",
    "nuclear = getelements(nud, sti_dataset1);\n",
    "\n",
    "elements = vcat(exogen,aggdetd,thermal,windsol,transm,cons,agginflow,fuel,nuclear)\n",
    "JulES.addscenariotimeperiod_vector!(elements, scenarioyearstart, scenarioyearstop);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15f341",
   "metadata": {},
   "source": [
    "### Initialize and run price prognosis models for all scenarios\n",
    "- Three levels of details: Long, medium and short term problems (run sequentially for each scenario)\n",
    "- All 30 scenarios (run in parallell)\n",
    "- Inputs:\n",
    "    - Power market representation / Europe dataset. (And how to aggregate it)\n",
    "    - Problem length and time resolution\n",
    "        - Long: 5 years long horizon with 6-weekly resolution for hydro, divided into 4 dynamic load blocks per 6 weeks for power. The dynamic load blocks groups together hours with similar residual load, which gives fewer periods but more variation between the periods. The alternative would be to for example have daily resolution for power, which ignores the price variation during the day.\n",
    "        - Med: 54 week long horizon with weekly resolution for hydro, divided into 4 dynamic load blocks per week for power\n",
    "        - Short: Week long horizon with daily resolution for hydro, and two-hourly for power\n",
    "- Outputs:\n",
    "    - Long, medium and short term prices for use in stochastic subsystem models.\n",
    "    - Storage values (water values) from medium for use as end condition in stochastic subsystem models.\n",
    "    - Thermal end states from short for use as end condition in market clearing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7270f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set horizons for price prognosis models\n",
    "# All\n",
    "shorthorizonduration = Millisecond(Day(7))\n",
    "\n",
    "# Long\n",
    "longhorizonduration = Millisecond(Week(5*52))\n",
    "longhydroperiodduration = Millisecond(Day(7*6))\n",
    "longrhsdata = DynamicExogenPriceAHData(Id(\"Balance\", \"PowerBalance_TYSKLAND\")) # TODO: If dynamic use tphasein\n",
    "longmethod = KMeansAHMethod()\n",
    "longclusters = 4\n",
    "longunitduration = Millisecond(Hour(6))\n",
    "longstartafter = shorthorizonduration\n",
    "longshrinkatleast = longhydroperiodduration - phaseinoffset\n",
    "longminperiod = phaseinoffset\n",
    "\n",
    "# longhorizon = (longhorizonduration, longhydroperiodduration, longrhsdata, longmethod, longclusters, longunitduration)\n",
    "# longobjects, lhh, lph = JulES.make_obj(elements, longhorizon...)\n",
    "longhorizon = (longhorizonduration, longhydroperiodduration, longrhsdata, longmethod, longclusters, longunitduration, longstartafter, longshrinkatleast, longminperiod)\n",
    "longobjects, lhh, lph = JulES.make_shrinkable_obj(elements, longhorizon...)\n",
    "\n",
    "JulES.simplify!(longobjects; aggsupplyn=4, removestoragehours=10, residualarealist=[])\n",
    "JulES.addPowerUpperSlack!(longobjects)\n",
    "\n",
    "# Medium\n",
    "medhorizonduration = Millisecond(Day(10*7*6))\n",
    "medhydroperiodduration = Millisecond(Day(7)); @assert medhorizonduration.value % longhydroperiodduration.value == 0\n",
    "medrhsdata = DynamicExogenPriceAHData(Id(\"Balance\", \"PowerBalance_TYSKLAND\"))\n",
    "medmethod = KMeansAHMethod()\n",
    "medclusters = 4\n",
    "medunitduration = Millisecond(Hour(4))\n",
    "medstartafter = shorthorizonduration\n",
    "medshrinkatleast = longhydroperiodduration - phaseinoffset\n",
    "medminperiod = phaseinoffset\n",
    "\n",
    "# medhorizon = (medhorizonduration, medhydroperiodduration, medrhsdata, medmethod, medclusters, medunitduration)\n",
    "# medobjects, mhh, mph = JulES.make_obj(elements, medhorizon...)\n",
    "medhorizon = (medhorizonduration, medhydroperiodduration, medrhsdata, medmethod, medclusters, medunitduration, medstartafter, medshrinkatleast, medminperiod)\n",
    "medobjects, mhh, mph = JulES.make_shrinkable_obj(elements, medhorizon...)\n",
    "\n",
    "JulES.simplify!(medobjects; aggsupplyn=4, removestoragehours=10, residualarealist=[])\n",
    "JulES.addPowerUpperSlack!(medobjects)\n",
    "\n",
    "# Short\n",
    "shorthydroperiodduration = Millisecond(Day(1)); @assert medhorizonduration.value % shorthorizonduration.value == 0\n",
    "shortpowerparts = 8\n",
    "shorthorizon = (shorthorizonduration, shorthydroperiodduration, shortpowerparts)\n",
    "\n",
    "shortobjects, shh, sph = JulES.make_obj(elements, shorthorizon...)\n",
    "JulES.simplify!(shortobjects; removestartup=false, residualarealist=[])\n",
    "JulES.addPowerUpperSlack!(shortobjects)\n",
    "\n",
    "# Start storages\n",
    "startstates = JSON.parsefile(joinpath(sti_dataset1, \"aggstartmagdict.json\"), dicttype=Dict{String, Float64})  # startstates for aggregated reservoirs\n",
    "JulES.startstates_max!(getstorages(shortobjects), tnormal, startstates)\n",
    "\n",
    "# Preallocate storage for problems and results on different cores. Use package DistributedArrays\n",
    "# Distribute scenarios\n",
    "allscenarios = JulES.distribute(totalscentimes)\n",
    "\n",
    "# Problems are built, updated, solved, and stored on a specific core. Moving a problem between cores is expensive, so we want it to only exist on one core. \n",
    "longprobs = JulES.distribute([HiGHS_Prob() for i in 1:length(allscenarios)], allscenarios)\n",
    "medprobs = JulES.distribute([HiGHS_Prob() for i in 1:length(allscenarios)], allscenarios)\n",
    "shortprobs = JulES.distribute([HiGHS_Prob() for i in 1:length(allscenarios)], allscenarios)\n",
    "\n",
    "# Results are moved between cores. These are much smaller than longprobs/medprobs/shortprobs and are inexpensive to move between cores.\n",
    "medprices = JulES.distribute([Dict() for i in 1:length(allscenarios)], allscenarios)\n",
    "shortprices = JulES.distribute([Dict() for i in 1:length(allscenarios)], allscenarios)\n",
    "medendvaluesobjs = JulES.distribute([EndValues() for i in 1:length(allscenarios)], allscenarios)\n",
    "nonstoragestates = JulES.distribute([Dict{StateVariableInfo, Float64}() for i in 1:length(allscenarios)], allscenarios)\n",
    "\n",
    "# Organise inputs and outputs\n",
    "probs = (longprobs, medprobs, shortprobs)\n",
    "objects = (longobjects, medobjects, shortobjects)\n",
    "horizons = (lhh, lph, mhh, mph, shh, sph)\n",
    "proginput = (numcores, allscenarios, phaseinoffset, startstates)\n",
    "progoutput = (medprices, shortprices, medendvaluesobjs, nonstoragestates)\n",
    "  \n",
    "# Which solver and settings should we use for each problem? Warmstart for long/med and presolve for short\n",
    "probmethodsprognosis = [HighsSimplexMethod(), HighsSimplexMethod(), HighsSimplexMethod(warmstart=false)]\n",
    "# probmethodsprognosis = [CPLEXSimplexMethod(), CPLEXSimplexMethod(), CPLEXSimplexMethod(warmstart=false)]\n",
    "\n",
    "# Initialize price prognosis models and run for first time step. Run scenarios in parallell\n",
    "@time JulES.pl_prognosis_init!(probmethodsprognosis, probs, objects, horizons, proginput, progoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0783f",
   "metadata": {},
   "source": [
    "### Plot medium term prices for some scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc28f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 1\n",
    "# index = collect(medprices[scenario][\"steprange\"])\n",
    "# prices = medprices[scenario][\"matrix\"]\n",
    "# labels = [name for name in medprices[scenario][\"names\"]]\n",
    "# p = plot(index,prices*100,label=reshape(labels, 1, length(labels)),legend=:outertopright)\n",
    "\n",
    "# for scenario in 2:5 # length(allscenarios)\n",
    "#     prices = medprices[scenario][\"matrix\"]\n",
    "#     labels = [name for name in medprices[scenario][\"names\"]]\n",
    "#     plot!(p,index,prices*100,label=reshape(labels, 1, length(labels)),legend=:outertopright)\n",
    "# end\n",
    "# display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70def2",
   "metadata": {},
   "source": [
    "### Plot short term prices for some scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6044f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 1\n",
    "# index = collect(shortprices[scenario][\"steprange\"])\n",
    "# prices = shortprices[scenario][\"matrix\"]\n",
    "# labels = [name for name in shortprices[scenario][\"names\"]]\n",
    "# p = plot(index,prices,label=reshape(labels, 1, length(labels)), ylabel=\"â‚¬/MWh\",legend=:outertopright)\n",
    "\n",
    "# for scenario in 2:5 # length(allscenarios)\n",
    "#     prices = shortprices[scenario][\"matrix\"]\n",
    "#     labels = [name for name in shortprices[scenario][\"names\"]]\n",
    "#     plot!(p, index, prices*100 ,label=reshape(labels, 1, length(labels)),legend=:outertopright)\n",
    "# end\n",
    "# display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3a119",
   "metadata": {},
   "source": [
    "### Stochastic subsystem models and market clearing model uses more detailed hydropower data\n",
    "\n",
    "NVEs Europe dataset (explained above) combined with detailed hydropower for Norway and Sweden. The full detailed dataset contains for Nortwestern Europe:\n",
    "- 32 price areas (9 exogen)\n",
    "- 73 transmission lines (19 with ramping)\n",
    "- 162 demands\n",
    "- 88 batteries (normal, and representing demand response and V2G)\n",
    "- 294 thermal plants (228 with start up costs)\n",
    "- 100 wind and solar plants (aggregated)\n",
    "- 1482 hydropower modules\n",
    "    - 965 with production\n",
    "    - 43 with pumps (includes PHS)\n",
    "    - 998 with reservoirs\n",
    "    - 788 restrictions (environmental, reservoir curves and ramping)\n",
    "    - 90 PQ-curves (mostly Sweden)\n",
    "    - Metadata for head dependency (nominal head, outlet level and reservoir curves) for some plants and pumps\n",
    "\n",
    "NVEs dataset for the hydropower system in 2022 is open, but we have not published datasets for 2025/2030/2040/2050 since it would reveal investment plans. The dataset exist in several formats:\n",
    "- Aggregated (for Res and RoR) production capacity, reservoir capacity, inflow and inflow profiles per price areas from https://www.nve.no/energi/analyser-og-statistikk/vaerdatasett-for-kraftsystemmodellene/\n",
    "- Detailed watercourse descriptions from https://www.nve.no/energi/energisystem/vannkraft/modell-av-det-norske-vannkraftsystemet/. The dataset exist in two DETD-formats (per EMPS area (also includes rest modules for small-scale hydro) or per watercourse), and simplified in an Excel-format. The dataset used in this demo is derived from the excel-format with some differences: \n",
    "    - Every water balance has its own module (i.e. a module with both regulated and unregulated inflow is split into two modules). \n",
    "    - It has pq-kurves, reservoir curves (for head dependency) and environmental restrictions\n",
    "    - It has ramping restrictions for hydropower release (only used in market clearing).\n",
    "    - It has metadata for head dependency (nominal head, outlet level and reservoir curves) for some plants and pumps\n",
    "- The inflow series for the detailed dataset can be found at https://www.nve.no/vann-og-vassdrag/hydrologiske-data/historiske-data/historiske-vannfoeringsdata-til-produksjonsplanlegging/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset for stochastic and market clearing models\n",
    "dse = JSON.parsefile(joinpath(sti_dataset, \"tidsserier_detd.json\"))\n",
    "detdseries = getelements(dse, sti_dataset);\n",
    "\n",
    "dda = JSON.parsefile(joinpath(sti_dataset, \"dataset_detd.json\"))\n",
    "detdstructure = getelements(dda);\n",
    "\n",
    "ipd = JSON.parsefile(joinpath(sti_dataset1, \"tilsigsprognoser$scenarioyear.json\"))\n",
    "inflow = getelements(ipd, sti_dataset1);\n",
    "\n",
    "detailedelements = vcat(exogen,detdseries,detdstructure,thermal,windsol,transm,cons,inflow,fuel,nuclear)\n",
    "JulES.addscenariotimeperiod_vector!(detailedelements, scenarioyearstart, scenarioyearstop);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec6e91",
   "metadata": {},
   "source": [
    "#### Get water values for detailed hydro (DETD) from aggregated hydro (TheMA)\n",
    "- With different representations of watercourses in different problems, we need a mapping\n",
    "- TODO: Only use the detailed hydropower dataset and aggregate it for the price prognosis models. Now this aggregation is done outside of the model which gives the user less flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d838bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between aggregated and detailed storages\n",
    "detailedrescopl = JSON.parsefile(joinpath(sti_dataset, \"magasin_elspot.json\"))\n",
    "\n",
    "# Global energy equivalent detailed reservoirs\n",
    "enekvglobaldict = Dict()\n",
    "for element in detailedelements\n",
    "    if element.typename == GLOBALENEQKEY\n",
    "        enekvglobaldict[split(element.instancename,\"GlobalEneq_\")[2]] = element.value[\"Value\"]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Detailed dataset has reservoirs for SE4, aggregated does not, TODO: Improve aggregation/mapping\n",
    "for k in keys(detailedrescopl)\n",
    "    if detailedrescopl[k] == \"SVER-SE4\"\n",
    "        detailedrescopl[k] = \"SVER-SE3\"\n",
    "    end\n",
    "end\n",
    "\n",
    "# Get dictionary with each detailed reservoir and their water value for each scenario\n",
    "# TODO: Detailed run-of-river reservoirs get water value from aggregated reservoir hydro\n",
    "function getendvaluesdicts(endvaluesobjs::Any, detailedrescopl::Dict, enekvglobaldict::Dict)\n",
    "    endvaluesdicts = Dict[]\n",
    "    for endvaluesobj in endvaluesobjs\n",
    "        instance = [getinstancename(getid(obj)) for obj in endvaluesobj.objects]\n",
    "        endvalues = endvaluesobj.values\n",
    "        endvaluesdict = Dict(instance .=> endvalues)\n",
    "\n",
    "        for (k,v) in detailedrescopl\n",
    "            endvaluesdict[\"Reservoir_\" * k] = endvaluesdict[\"Reservoir_\" * v * \"_hydro_reservoir\"] * enekvglobaldict[k]\n",
    "        end\n",
    "        push!(endvaluesdicts, endvaluesdict)\n",
    "    end\n",
    "    \n",
    "    return endvaluesdicts\n",
    "end\n",
    "medendvaluesdicts = getendvaluesdicts(medendvaluesobjs, detailedrescopl, enekvglobaldict);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6924e77",
   "metadata": {},
   "source": [
    "### Scenario modelling\n",
    "\n",
    "We use scenario modelling to consider uncertainty from 30 scenarios with only 7 scenarios. Scenarios can be chosen and weighted with different methods.\n",
    "- In this prototype we use InflowClusteringMethod which cluster together scenarios with similar total energy inflows in the whole dataset (both level and profile). One scenario from each cluster will represent the others with the weight based on the size of the cluster.\n",
    "\n",
    "This is implemented with modularity in mind, so you can chose other methods aswell or implement your own:\n",
    "- NoScenarioModellingMethod keeps all the 30 scenarios\n",
    "- SumInflowQuantileMethod calculates the total inflow in each scenario, puts them on a Bell curve and lets the user choose scenarios based on quantiles of the distribution. The user can also decide how to weight the scenarios with a polynomial function (for example weight the extremes more, only the wet years or only the dry years more)\n",
    "\n",
    "TODO: \n",
    "- Now we do the scenario modelling based on the energy inflow in the whole dataset. This works ok since the most important subsystem models are the watercourses in the Nordics. But the scenarios chosen will work worse for the battery systems. In the future we would like to have different scenario modelling for different technologies and systems in different geographical areas. Other alternatives could be to do the scenario modelling based on the price series, or with the residual load (including energy inflow.)\n",
    "- We also want to implement more complex scenario generation. This modular design of JulES gives us the flexibility to in the future generate inflow series for each watercourse with state information like snow reservoir levels and weather forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422de037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario reduction to this amount\n",
    "numscen = 7\n",
    "\n",
    "# Modelobjects that can be used to reduce scenarios\n",
    "scenarioelements = copy(detailedelements)\n",
    "\n",
    "# Horizons are needed to build modelobjects, but not used in scenario modelling\n",
    "dummyperiods = 10\n",
    "dummyperiodduration = Millisecond(Hour(24))\n",
    "power_horizon = SequentialHorizon(dummyperiods, dummyperiodduration)\n",
    "hydro_horizon = SequentialHorizon(dummyperiods, dummyperiodduration)\n",
    "\n",
    "JulES.set_horizon!(scenarioelements, \"Power\", power_horizon)\n",
    "JulES.set_horizon!(scenarioelements, \"Battery\", power_horizon)\n",
    "JulES.set_horizon!(scenarioelements, \"Hydro\", hydro_horizon)\n",
    "\n",
    "scenarioobjects = collect(values(getmodelobjects(scenarioelements)))\n",
    "\n",
    "# Scenario modelling method\n",
    "scendelta = MsTimeDelta(Day(364)) # scenario modelling based on the next year, even though the scenario problems can be longer\n",
    "if numscen >= totalscen\n",
    "    global scenmodmethod = JulES.NoScenarioModellingMethod(totalscen, totalscentimes)\n",
    "else\n",
    "    parts = 4 # divide scendelta into this many parts, calculate sum inflow for each part of the inflow series, then use clustering algorithm\n",
    "    global scenmodmethod = JulES.InflowClusteringMethod(numscen, parts)\n",
    "end\n",
    "@time JulES.scenariomodelling!(scenmodmethod, scenarioobjects, numscen, totalscentimes, scendelta); # see JulES/scenariomodelling.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c66180",
   "metadata": {},
   "source": [
    "### Stochastic subsystem models with Benders decomposition\n",
    "- Each unique storage system (watercourses or batteries) is solved as a two-stage stochastic LP with Benders decomposition\n",
    "- The subsystems are optimized against exogen prices from the price prognosis scenarios\n",
    "- We group storage systems into two. These are solved with different degree of detail\n",
    "    - Med-term - mostly hydro\n",
    "        - 52 week long horizon, weekly resolution, price from medium term price prognosis\n",
    "    - Short-term - mostly batteries and PHS\n",
    "        - Week long horizon, two-hourly resolution, price from short term price prognosis\n",
    "- Outputs:\n",
    "    - Cuts (battery or hydro) for use as end condition in market clearing problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1c496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cut parameters\n",
    "maxcuts = 13 # preallocate fixed number of cuts, no cut selection\n",
    "lb = -1e5 # lower bound of the future value in the first iteration\n",
    "reltol = 0.0001 # relative tolerance\n",
    "\n",
    "# Parameters for stochastic subsystem problems (could also split totalduration into master- and subduration)\n",
    "smpdp = Millisecond(Hour(3)) # short/med - master/sub - period duration - power/hydro (commodity)\n",
    "smpdh = Millisecond(Hour(3))\n",
    "sspdp = Millisecond(Hour(3))\n",
    "sspdh = Millisecond(Hour(3)) # both master and subproblems for PHS and batteries has 2 hour resolution\n",
    "mmpdp = Millisecond(Hour(24))\n",
    "mmpdh = Millisecond(Hour(24)) # daily resolution in hydro master problems\n",
    "mspdp = Millisecond(Day(7))\n",
    "mspdh = Millisecond(Day(7)) # 7-day resolution in hydro subproblems\n",
    "shorttotalduration = shorthorizonduration # total duration of master and subproblem\n",
    "medtotalduration = medhorizonduration - Millisecond(Day(14)) # we reuse prices for two weeks, so have to be two weeks shorter than price prognosis problem\n",
    "\n",
    "# Make sure time resolution of hydro and power are compatible (TODO: Could add function that makes them compatible)\n",
    "@assert ceil(Int64, phaseinoffset/smpdp) == ceil(Int64, phaseinoffset/smpdh)\n",
    "@assert ceil(Int64, (shorttotalduration-phaseinoffset)/sspdp) == ceil(Int64, (shorttotalduration-phaseinoffset)/sspdh)\n",
    "@assert ceil(Int64, phaseinoffset/mmpdp) == ceil(Int64, phaseinoffset/mmpdh)\n",
    "@assert ceil(Int64, (medtotalduration-phaseinoffset)/mspdp) == ceil(Int64, (medtotalduration-phaseinoffset)/mspdh)\n",
    "\n",
    "# Convert DistributedArray of prices to local process\n",
    "medpriceslocal = convert(Vector{Dict}, medprices)\n",
    "shortpriceslocal = convert(Vector{Dict}, shortprices)\n",
    "\n",
    "# Inputs\n",
    "stochasticelements = JulES.removeelements!(copy(detailedelements))\n",
    "storageinfo = (startstates, medendvaluesdicts)\n",
    "shortterminputs = (stochasticelements, shorttotalduration, smpdp, smpdh, sspdp, sspdh, scenmodmethod.scentimes, phaseinoffset, shortpriceslocal, true)\n",
    "medterminputs = (stochasticelements, medtotalduration, mmpdp, mmpdh, mspdp, mspdh, scenmodmethod.scentimes, phaseinoffset, medpriceslocal, false)\n",
    "\n",
    "ustoragesystemobjects = Tuple{Vector, Vector{Vector}}[]\n",
    "ushorts = Bool[]\n",
    "# Make modelobjects for short-term subsystems\n",
    "@time stochasticmodelobjects = JulES.makemastersubobjects!(shortterminputs, ustoragesystemobjects, ushorts)\n",
    "# TODO: Print info about number of short and long term systems\n",
    "\n",
    "# Make modelobjects for medium-term subsystems\n",
    "@time JulES.makemastersubobjects!(medterminputs, ustoragesystemobjects, ushorts)\n",
    "\n",
    "# Add detailed startstates\n",
    "merge!(startstates, JSON.parsefile(joinpath(sti_dataset1, \"startmagdict.json\"))) # also read detailed startstates used in the other problems\n",
    "JulES.startstates_max!(getstorages(stochasticmodelobjects), tnormal, startstates)\n",
    "\n",
    "# Distribute subsystems with inputs and outputs on different cores\n",
    "storagesystemobjects, shorts = JulES.distribute_subsystems(ustoragesystemobjects, ushorts) # somewhat smart distribution of subsystems to cores based on how many modelobjects in eac subsystem\n",
    "masters = JulES.distribute([HiGHS_Prob() for i in 1:length(storagesystemobjects)], storagesystemobjects)\n",
    "subs = JulES.distribute([[] for i in 1:length(storagesystemobjects)], storagesystemobjects)\n",
    "states = JulES.distribute([Dict{StateVariableInfo, Float64}() for i in 1:length(storagesystemobjects)], storagesystemobjects)\n",
    "cuts = JulES.distribute([SimpleSingleCuts() for i in 1:length(storagesystemobjects)], storagesystemobjects)\n",
    "storagesystems = JulES.distribute([Dict() for i in 1:length(storagesystemobjects)], storagesystemobjects)\n",
    "\n",
    "# Which solver and settings should we use for each problem?\n",
    "# probmethodsstochastic = [CPLEXSimplexMethod(), CPLEXSimplexMethod()]\n",
    "probmethodsstochastic = [HighsSimplexMethod(), HighsSimplexMethod()]\n",
    "\n",
    "# Initialize subsystem problems and run for first time step. Run subsystems in parallell\n",
    "@time JulES.pl_stochastic_init!(probmethodsstochastic, numcores, storagesystemobjects, shorts, masters, subs, states, cuts, storageinfo, lb, maxcuts, reltol, scenmodmethod.scentimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab6d37",
   "metadata": {},
   "source": [
    "### Market clearing problem\n",
    "- Deterministic LP\n",
    "- Two days, full detail (hydro and thermal), two-hourly resolution for power, 6 hourly resolution for hydro\n",
    "- Inputs:\n",
    "    - Detailed power market representation\n",
    "    - Water values and battery storage values from stochastic subsystem problems\n",
    "    - Thermal end condition from short term price prognosis model\n",
    "- Outputs:\n",
    "    - Two day detailed power market simulation (price, production, reservoir etc...)\n",
    "    - Start state for next time step (reservoirs and other state variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data to local core\n",
    "@time masterslocal = convert(Vector{Prob}, masters)\n",
    "@time cutslocal = convert(Vector{SimpleSingleCuts}, cuts)\n",
    "@time nonstoragestateslocal = convert(Vector{Dict}, nonstoragestates)\n",
    "\n",
    "# Initialize market clearing problem and run for first time step\n",
    "cpdp = Millisecond(Hour(3)) # clearing period duration power/battery\n",
    "cnpp = ceil(Int64, phaseinoffset/cpdp) # clearing numperiods power/battery\n",
    "cpdh = Millisecond(Hour(6)) # clearing period duration hydro\n",
    "# cpdh = Millisecond(Hour(2)) # clearing period duration hydro\n",
    "cnph = ceil(Int64, phaseinoffset/cpdh) # clearing numperiods hydro\n",
    "probmethodclearing = HighsSimplexMethod(warmstart=false)\n",
    "# probmethodclearing = HighsSimplexSIPMethod(warmstart=false, concurrency=min(8, numcores)) # Which solver and settings should we use for each problem?\n",
    "# probmethodclearing = CPLEXIPMMethod(warmstart=false, concurrency=min(8, numcores))\n",
    "@time clearing, nonstoragestatesmean, varendperiod = JulES.clearing_init(probmethodclearing, detailedelements, tnormal, phaseinoffset, cpdp, cpdh, startstates, masterslocal, cutslocal, nonstoragestateslocal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update start states for next time step, also mapping to aggregated storages and max capacity in aggregated\n",
    "JulES.getstartstates!(clearing, detailedrescopl, enekvglobaldict, startstates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a28774",
   "metadata": {},
   "source": [
    "#### Head dependency in clearing_init!() and clearing!()\n",
    "\n",
    "Inside the market clearing we have implemented head dependency:\n",
    "- These functions sets state/head dependent energy equivalents for production and pumping \n",
    "    - statedependentprod_init!(clearing, 65, t)\n",
    "    - statedependentpump_init!(clearing, 65, t)\n",
    "- We use the headloss cost method ReservoirCurveSlopeMethod which increases the watervalue if a small increase in reservoir filling would give a higher head at the current reservoir filling. The head loss cost is based on the slope of the reservoir curve (reservoir height [m] to filling [Mm3]) at the current reservoir filling. To get the headloss cost, we multiply the water value with a factor of the percentage change in the height for a 2% change in the reservoir filling divided by 2% (a bit simplified). An example of a reservoir with a steep reservoir curve is Storglomvatn belonging to Svartisen, so the headloss cost will incentivise a higher reservoir filling to get a higher head and energy equivalent at production.\n",
    "    - updateheadlosscosts!(ReservoirCurveSlopeMethod(), clearing, masterslocal, t)\n",
    "    \n",
    "See the code at TuLiPa/reasoning_nvehydro.jl\n",
    "\n",
    "TODO: Make an interface for head dependency to support different methods. The method used in this demo is relatively simple since we only consider head dependency in the market clearing, but we have methods that also consider head dependency in the master and subproblems of the stochastic subsystem models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9f2a0",
   "metadata": {},
   "source": [
    "### Initialize and collect results: Prices and start states (e.g. reservoirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and collect prices and start states\n",
    "price = Dict()\n",
    "powerhorizonix = argmax(getnumperiods(h) for h in gethorizons(clearing))\n",
    "JulES.getareaprices!(price, clearing, gethorizons(clearing)[powerhorizonix], tnormal)\n",
    "areanames = price[\"names\"]\n",
    "\n",
    "ix = Vector{DateTime}(undef,Int(length(price[\"steprange\"])*steps))\n",
    "ix[1:length(price[\"steprange\"])] .= price[\"steprange\"]\n",
    "\n",
    "(pricex,pricey) = size(price[\"matrix\"])\n",
    "pricematrix = zeros(Int(pricex*steps),pricey)\n",
    "pricematrix[1:pricex,:] .= price[\"matrix\"]\n",
    "\n",
    "statenames = collect(keys(startstates))\n",
    "statematrix = zeros(length(values(startstates)), Int(steps))\n",
    "statematrix[:,1] .= collect(values(startstates));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25fb5f",
   "metadata": {},
   "source": [
    "#### Collect more detailed results\n",
    "- Prices, supply, demand, transmission and hydro storage levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clearingobjects = Dict(zip([getid(obj) for obj in getobjects(clearing)],getobjects(clearing))) # collect results from all areas\n",
    "# resultobjects = getpowerobjects(clearingobjects,[\"SORLAND\"]); # only collect results for one area\n",
    "resultobjects = getobjects(clearing) # collect results for all areas\n",
    "\n",
    "prices, rhstermvalues, production, consumption, hydrolevels, batterylevels, powerbalances, rhsterms, rhstermbalances, plants, plantbalances, plantarrows, demands, demandbalances, demandarrows, hydrostorages, batterystorages = init_results(steps, clearing, clearingobjects, resultobjects, cnpp, cnph, cpdp, tnormal, true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb90c8e",
   "metadata": {},
   "source": [
    "### Simulate next time steps (16 steps = 32 days)\n",
    "- Simulate next time steps, store results and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time problems\n",
    "prognosistimes = JulES.distribute([zeros(steps-1, 3, 3) for i in 1:length(allscenarios)], allscenarios) # update, solve, total per step for long, med, short\n",
    "stochastictimes = JulES.distribute([zeros(steps-1, 7) for i in 1:length(storagesystemobjects)], storagesystemobjects) # update master, update sub, iterate total, solve master, solve sub, iterations, total per system\n",
    "clearingtimes = zeros(steps-1, 3); # update, solve, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d5a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do scenario modelling and calculate new cuts every 8 days (other reuse scenarios and cuts)\n",
    "skipmed = Millisecond(Day(0))\n",
    "skipmax = Millisecond(Day(6))\n",
    "\n",
    "stepnr = 2; # already ran first step in initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675359d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "totaltime = @elapsed while stepnr <= steps # while step <= steps and count elapsed time\n",
    "\n",
    "    # Increment simulation/main scenario and uncertainty scenarios\n",
    "    tnormal += phaseinoffset\n",
    "\n",
    "    for i in 1:length(totalscentimes)\n",
    "        (scentnormal, scentphasein, scenario) = totalscentimes[i]\n",
    "        scentnormal += phaseinoffset\n",
    "        scentphasein = PhaseinPrognosisTime(getdatatime(scentnormal), getdatatime(scentnormal), getscenariotime(scentnormal), getscenariotime(scentnormal), phaseinoffset, phaseindelta, phaseinsteps)\n",
    "        totalscentimes[i] = (scentnormal, scentphasein, scenario)\n",
    "    end\n",
    "\n",
    "    # Increment skipmed - should we reuse watervalues this time step?\n",
    "    skipmed += Millisecond(phaseinoffset)\n",
    "    if skipmed > skipmax\n",
    "        skipmed = Millisecond(0)\n",
    "    end\n",
    "\n",
    "    # Print here to avoid wrong order\n",
    "    println(tnormal)\n",
    "\n",
    "    # Deterministic long/mid/short - calculate scenarioprices for all 30 scenarios\n",
    "    allscenarios = JulES.distribute(totalscentimes, allscenarios) # TODO: Find better solution\n",
    "    # @time JulES.pl_prognosis!(numcores, longprobs, medprobs, shortprobs, medprices, shortprices, nonstoragestates, startstates, allscenarios, skipmed)\n",
    "    @time JulES.pl_prognosis!(numcores, longprobs, medprobs, shortprobs, medprices, shortprices, nonstoragestates, startstates, allscenarios, skipmed, prognosistimes, stepnr-1)\n",
    "\n",
    "    # Stochastic sub systems - calculate storage value    \n",
    "    if skipmed.value == 0\n",
    "        # Choose new scenarios\n",
    "        @time JulES.scenariomodelling!(scenmodmethod, scenarioobjects, numscen, totalscentimes, scendelta)\n",
    "        \n",
    "        medpriceslocal = convert(Vector{Dict}, medprices)\n",
    "        medendvaluesdicts = JulES.getendvaluesdicts(medendvaluesobjs, detailedrescopl, enekvglobaldict)\n",
    "    else\n",
    "        # Increment existing scenarios\n",
    "        for i in 1:length(scenmodmethod.scentimes)\n",
    "            (scentnormal, scentphasein, scenario) = scenmodmethod.scentimes[i]\n",
    "            scentnormal += phaseinoffset\n",
    "            scentphasein = PhaseinPrognosisTime(getdatatime(scentnormal), getdatatime(scentnormal), getscenariotime(scentnormal), getscenariotime(scentnormal), phaseinoffset, phaseindelta, phaseinsteps)\n",
    "            scenmodmethod.scentimes[i] = (scentnormal, scentphasein, scenario)\n",
    "        end\n",
    "    end\n",
    "    shortpriceslocal = convert(Vector{Dict}, shortprices)\n",
    "\n",
    "    @time JulES.pl_stochastic!(numcores, masters, subs, states, cuts, startstates, medpriceslocal, shortpriceslocal, medendvaluesdicts, shorts, reltol, scenmodmethod.scentimes, skipmed, stochastictimes, stepnr-1)\n",
    "\n",
    "    # Market clearing\n",
    "    @time masterslocal = convert(Vector{Prob}, masters)\n",
    "    cutslocal = convert(Vector{SimpleSingleCuts}, cuts)\n",
    "    nonstoragestateslocal = convert(Vector{Dict}, nonstoragestates)\n",
    "\n",
    "    @time JulES.clearing!(clearing, tnormal, startstates, masterslocal, cutslocal, nonstoragestateslocal, nonstoragestatesmean, detailedrescopl, enekvglobaldict, varendperiod, clearingtimes, stepnr-1)\n",
    "    \n",
    "    # Results\n",
    "    JulES.updateareaprices!(price, clearing, gethorizons(clearing)[powerhorizonix], tnormal)\n",
    "    ix[Int(length(price[\"steprange\"])*(stepnr-1)+1):Int(length(price[\"steprange\"])*stepnr)] .= price[\"steprange\"]\n",
    "    pricematrix[Int(pricex*(stepnr-1)+1):Int(pricex*(stepnr)),:] .= price[\"matrix\"]\n",
    "    statematrix[:,Int(stepnr)] .= collect(values(startstates))\n",
    "    \n",
    "    update_results!(stepnr, clearing, prices, rhstermvalues, production, consumption, hydrolevels, batterylevels, powerbalances, rhsterms, plants, plantbalances, plantarrows, demands, demandbalances, demandarrows, hydrostorages, batterystorages, clearingobjects, cnpp, cnph, cpdp, tnormal)   \n",
    "    \n",
    "    # Increment step\n",
    "    stepnr += 1\n",
    "end\n",
    "\n",
    "# Total time use and per step\n",
    "println(string(\"The simulation took: \", totaltime/60, \" minutes\"))\n",
    "println(string(\"Time usage per timestep: \", totaltime/steps, \" seconds\"))\n",
    "\n",
    "# Prognosis and clearing times\n",
    "clearingtimes1 = mean(clearingtimes, dims=1)\n",
    "\n",
    "skipfactor = (skipmax+Millisecond(phaseinoffset))/Millisecond(phaseinoffset)\n",
    "factors = [skipfactor,skipfactor,1]\n",
    "dims = size(prognosistimes[1])\n",
    "dims = (dims..., length(prognosistimes))\n",
    "prognosistimes1 = reshape(cat(prognosistimes..., dims=4), dims)\n",
    "prognosistimes2 = transpose(dropdims(mean(prognosistimes1,dims=(1,4)),dims=(1,4))).*factors\n",
    "progclear = vcat(prognosistimes2, mean(clearingtimes, dims=1))\n",
    "df = DataFrame(model=[\"long\",\"med\",\"short\",\"clearing\"], update=progclear[:,1], solve=progclear[:,2], total=progclear[:,3])\n",
    "df[!, :other] = df[!, :total] - df[!, :solve] - df[!, :update]\n",
    "display(df[!, [1, 2, 3, 5, 4]])\n",
    "\n",
    "# Stochastic times\n",
    "core_dists = JulES.distribute([0 for i in 1:length(storagesystemobjects)], storagesystemobjects)\n",
    "@sync @distributed for core in 1:max(numcores-1,1)\n",
    "    core_dist = JulES.localpart(core_dists)\n",
    "\n",
    "    localix = 0\n",
    "    for range in JulES.localindices(core_dists)\n",
    "        for ix in range\n",
    "            localix += 1\n",
    "            core_dist[localix] = myid()\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "dims = size(stochastictimes[1])\n",
    "dims = (dims..., length(stochastictimes))\n",
    "st1 = reshape(cat(stochastictimes..., dims=4), dims)\n",
    "st2 = transpose(dropdims(mean(st1, dims=1), dims=1))\n",
    "df = DataFrame(umaster=st2[:,1], usub=st2[:,2], conv=st2[:,3], count=st2[:,4], smaster=st2[:,5], ssub=st2[:,6], total=st2[:,7], short=ushorts, core=core_dists)\n",
    "df[df.short .== false, [:umaster, :usub, :conv, :count, :smaster, :ssub, :total]] .= df[df.short .== false, [:umaster, :usub, :conv, :count, :smaster, :ssub, :total]] .* skipfactor\n",
    "dfsort = sort(df, :total, rev=true)\n",
    "display(dfsort)\n",
    "display(plot(dfsort[!, :total]))\n",
    "\n",
    "df1 = combine(groupby(df, :core), \n",
    "              :umaster => sum, \n",
    "              :usub => sum, \n",
    "              :conv => sum, \n",
    "              :count => sum, \n",
    "              :smaster => sum, \n",
    "              :ssub => sum, \n",
    "              :total => sum)\n",
    "dfsort = sort(df1, :total_sum, rev=true)\n",
    "display(dfsort)\n",
    "display(plot(dfsort[!, :total_sum]))\n",
    "display(mean.(eachcol(select(df1, Not(:core)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6257ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prognosistimes1[:,:,1,28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fbff9",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "In the first phase of JulES we have prioritized implementing functionality and test that they give the intended results, and compared results against other long-term models (TheMA and Samnett, which give a sufficient basis for comparison) on a big dataset. The price formation, reservoir operation and runtime of JulES seems promising, but there remains a lot of testing to see all the impacts of the concept implementation, model parameters, scenario modelling and head dependency on water values, prices, reservoir operation and runtime. The testing has been restricted by the runtime of the model, which we will have to improve to test different parts of the model more efficiently. In the next phase we want to test JulES as a short/medium-term paralell-simulation prognosis model. The results can then be compared to our other prognosis model (EMPS) and quickly be compared to the real market and historical data.\n",
    "\n",
    "Throughout the testing we have achieved the wanted price volatility in the thermal dominated part of the dataset (Western Europe). On the other hand, the Nordics have had very flat prices due to too much flexibility in the hydropower modelling. We have therefore added hydropower production ramping restrictions in the market clearing in an attempt to reduce the flexibility of the run-of-river hydropower plants. This results in much more price volatiliy, but at a big computational cost. Ramping restrictions on transmission lines has the same effect.\n",
    "\n",
    "Time usage with the current implementation in the demo and serial simulation of 30 weather years (~5500 two day long time steps):\n",
    "- Same as demo: 2 hourly power resolution and 6 hourly hydro resolution in market clearing and hydro ramping restrictions\n",
    "    - 24 hours total or 16 sec per time step or 55 sec per week\n",
    "- 2 hourly hydro resolution in market clearing and hydro ramping restrictions (no other difference to demo)\n",
    "    - 36 hours total or 24 sec per time step or 84 sec per week\n",
    "- 24 hourly hydro resolution in market clearing and no hydro ramping restrictions (no other difference to demo)\n",
    "    - 18 hours total or 12 sec per time step or 41 sec per week\n",
    "\n",
    "This is promising considering the big dataset, and the list of possible optimization we have in mind:\n",
    "- It is interesting what these computational times would be with a commercial solver (we now use HiGHS), and with more and faster processor cores in parallel (now 30 2.2 GHz processor cores). \n",
    "- We could clear the market for 24 hours at a time instead of 48 hours like now, which could reduce the computational time depending on if the market clearing has a higher runtime than the stochastic subsystem and price prognosis models (this is the case when we have a very detailed market clearing). \n",
    "- We could try different configurations of ramping restrictions, and test if time delays in watercourses can achieve the same effects at a lower computation cost. Considering unavailability of hydropower or reserve market obligations, should also decrease the flexibility of the hydropower system. Detailed transmission system modelling should also be implemented in the future.\n",
    "- We could run the model only for the Nordics, which would reduce the size of the dataset substantially and give results that are comparable to other models we use.\n",
    "\n",
    "The price levels in the Nordics are higher than in other models. This is partly due to the high flexibility in the hydropower modelling, which gives stable high prices and not many zero-prices. Another reason is that the stochastic subsystem models could need some improvements, for example longer and more detailed horizons. This should give water values that gives better long term signals. More load shedding can also be a contributor to higher prices, but this can be prevented with scenario modelling and head dependencies.\n",
    "\n",
    "We have also seen the effects of scenario modelling and head dependencies. Scenario modelling can be used to reduce the runtime and adjust the risk taking, which gives more realistic reservoir operation and avoid the extremes of flooding and load shedding. Head dependency can be used to get a more realistic reservoir operation and higher production, and also gives lower risk of load shedding. These have to be tested further.\n",
    "\n",
    "We are also very happy with the modelling choice of modularity, using time-series datasets and using Julia. This has made TuLiPa and JulES very pleasant to work with, as they provide a great deal of flexibility in adding complex functionality without having to make extensive changes to the existing code. Additionally, the models can be run with different methods and time resolutions without adaptations of the dataset. These design choices contribute to the model's suitability for further development and modeling the future power system when new modeling requirements arise.\n",
    "\n",
    "However, the project's codebase needs to be professionalized with better structure to make the model more user-friendly, allowing not only developers to run the model. Unit testing is also important to ensure that the model functions as intended. So far, we have been working on the model concept alone, so it will be crucial to involve analysts who will use the models and developers outside of NVE who can contribute to further developing the concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14393bd",
   "metadata": {},
   "source": [
    "### Postprocess detailed results\n",
    "- Combine fixed contributions (e.g. wind, solar and demand) together with supply and demand variables\n",
    "- Make time axis for price, supply/demand and reservoir levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ef907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep rhsterms that have at least one value (TODO: Do the same for sypply and demands)\n",
    "rhstermtotals = dropdims(sum(rhstermvalues,dims=1),dims=1)\n",
    "rhstermsupplyidx = []\n",
    "rhstermdemandidx = []\n",
    "\n",
    "for k in 1:length(rhsterms)\n",
    "    if rhstermtotals[k] > 0\n",
    "        push!(rhstermsupplyidx, k)\n",
    "    elseif rhstermtotals[k] < 0\n",
    "        push!(rhstermdemandidx, k)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Put rhsterms together with supplies and demands\n",
    "rhstermsupplyvalues = rhstermvalues[:,rhstermsupplyidx]\n",
    "rhstermdemandvalues = rhstermvalues[:,rhstermdemandidx]*-1\n",
    "\n",
    "rhstermsupplynames = [getinstancename(rhsterm) for rhsterm in rhsterms[rhstermsupplyidx]]\n",
    "rhstermsupplybalancenames = [split(getinstancename(r), \"PowerBalance_\")[2] for r in rhstermbalances[rhstermsupplyidx]]\n",
    "rhstermdemandnames = [getinstancename(rhsterm) for rhsterm in rhsterms[rhstermdemandidx]]\n",
    "rhstermdemandbalancenames = [split(getinstancename(r), \"PowerBalance_\")[2] for r in rhstermbalances[rhstermdemandidx]]\n",
    "\n",
    "supplynames = [[getinstancename(plant) for plant in plants];rhstermsupplynames]\n",
    "supplybalancenames = [[split(getinstancename(p), \"PowerBalance_\")[2] for p in plantbalances];rhstermsupplybalancenames]\n",
    "supplyvalues = hcat(production,rhstermsupplyvalues)\n",
    "\n",
    "demandnames = [[getinstancename(demand) for demand in demands];rhstermdemandnames]\n",
    "demandbalancenames = [[split(getinstancename(p), \"PowerBalance_\")[2] for p in demandbalances];rhstermdemandbalancenames]\n",
    "demandvalues = hcat(consumption, rhstermdemandvalues)\n",
    "\n",
    "# Prepare for plotting results\n",
    "hydronames = [getinstancename(hydro) for hydro in hydrostorages]\n",
    "batterynames = [getinstancename(battery) for battery in batterystorages]\n",
    "powerbalancenames = [split(getinstancename(getid(powerbalance)), \"PowerBalance_\")[2] for powerbalance in powerbalances]\n",
    "\n",
    "# Convert reservoir filling to TWh\n",
    "hydrolevels1 = copy(hydrolevels)\n",
    "for (i,hydroname) in enumerate(hydronames)\n",
    "    if haskey(getbalance(clearingobjects[hydrostorages[i]]).metadata, GLOBALENEQKEY)\n",
    "        hydrolevels1[:,i] .= hydrolevels1[:,i]*getbalance(clearingobjects[hydrostorages[i]]).metadata[GLOBALENEQKEY]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Time\n",
    "x1 = [getisoyearstart(datayearstart) + Week(weekstart-1) + cpdp*(t-1) for t in 1:first(size(supplyvalues))] # power/load resolution\n",
    "x2 = [getisoyearstart(datayearstart) + Week(weekstart-1) + cpdh*(t-1) for t in 1:first(size(hydrolevels))]; # reservoir resolution\n",
    "x3 = [getisoyearstart(datayearstart) + Week(weekstart-1) + phaseinoffset*(t-1) for t in 1:steps]; # state resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ada54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sti_output = joinpath(JSON.parsefile(joinpath(pwd(), \"jules_config.json\"), use_mmap=false)[1], \"prognosemodell\", \"prognoser\", \"Uke_$weekstart\", \"output\")\n",
    "\n",
    "# # Store results with binary h5 format\n",
    "# datetimeformat = \"yyyy-mm-ddTHH:MM:SS\"\n",
    "# modelname = scenarioyear\n",
    "\n",
    "# data = Dict()\n",
    "# data[\"areanames\"] = powerbalancenames |> Vector{String}\n",
    "# data[\"pricematrix\"] = prices\n",
    "# data[\"priceindex\"] = Dates.format.(x1, datetimeformat) # not necessary to store as string\n",
    "\n",
    "# data[\"resnames\"] = hydronames\n",
    "# data[\"resmatrix\"] = hydrolevels1\n",
    "# data[\"resindex\"] =  Dates.format.(x2, datetimeformat)\n",
    "\n",
    "# data[\"statenames\"] = statenames\n",
    "# data[\"statematrix\"] = permutedims(statematrix)\n",
    "# data[\"stateindex\"] =  Dates.format.(x3, datetimeformat)\n",
    "\n",
    "# data[\"supplyvalues\"] = supplyvalues\n",
    "# data[\"supplynames\"] = supplynames\n",
    "# data[\"supplybalancenames\"] = supplybalancenames\n",
    "\n",
    "# data[\"demandvalues\"] = demandvalues\n",
    "# data[\"demandnames\"] = demandnames\n",
    "# data[\"demandbalancenames\"] = demandbalancenames\n",
    "\n",
    "# data[\"prognosistimes\"] = prognosistimes1\n",
    "# data[\"stochastictimes\"] = st1\n",
    "# data[\"clearingtimes\"] = clearingtimes\n",
    "\n",
    "# data[\"\"]\n",
    "\n",
    "# using FileIO, HDF5\n",
    "# @time h5open(joinpath(sti_output, \"$modelname.h5\"), \"w\") do file\n",
    "#     for (k,v) in data\n",
    "#         display(k)\n",
    "#         write(file, k, v)\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# # # Read results so that they can be compared to other models (we have another script that compares JulES with Samnett and TheMA)\n",
    "# # # Read using JLD2\n",
    "# # using JLD2\n",
    "# # @time JulESdata = JLD2.load(\"$modelname.h5\")\n",
    "\n",
    "# # # Read using HDF5\n",
    "# # JulESdata = Dict{String, Any}()\n",
    "# # @time c = h5open(\"$modelname.h5\", \"r\") do file\n",
    "# #     for key in keys(data)\n",
    "# #         JulESdata[key] = read(file, key)\n",
    "# #     end\n",
    "# # end\n",
    "\n",
    "# # Store as CSV\n",
    "# areaprices = rename!(DataFrame(prices, :auto),powerbalancenames)\n",
    "# areaprices[!,:time] = x1\n",
    "# CSV.write(joinpath(sti_output, \"price$scenarioyear.csv\"), areaprices)\n",
    "\n",
    "# demand = rename!(DataFrame(demandvalues, :auto),demandnames)\n",
    "# demand[!,:time] = x1\n",
    "# demand = stack(demand,Not(:time))\n",
    "# demandcopl = DataFrame(variable=demandnames, area=demandbalancenames)\n",
    "# demand = leftjoin(demand, demandcopl, on=:variable)\n",
    "# CSV.write(joinpath(sti_output, \"demand$scenarioyear.csv\"), demand)\n",
    "\n",
    "# supply = rename!(DataFrame(supplyvalues, :auto),supplynames)\n",
    "# supply[!,:time] = x1\n",
    "# supply = stack(supply,Not(:time))\n",
    "# supplycopl = DataFrame(variable=supplynames, area=supplybalancenames)\n",
    "# supply = leftjoin(supply, supplycopl, on=:variable)\n",
    "# CSV.write(joinpath(sti_output, \"supply$scenarioyear.csv\"), supply)\n",
    "\n",
    "# hydro = rename!(DataFrame(hydrolevels, :auto),hydronames)\n",
    "# hydro[!,:time] = x2\n",
    "# CSV.write(joinpath(sti_output, \"hydro$scenarioyear.csv\"), hydro);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fe98f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot prices\n",
    "idxwohub = findall(x -> !occursin(\"HUB\", x), powerbalancenames) # remove hubs, not active in 2025 dataset\n",
    "display(plot(x1, prices[:,idxwohub]*100, labels=reshape(powerbalancenames[idxwohub],1,length(powerbalancenames[idxwohub])), size=(800,500), title=\"Prices\", ylabel=\"â‚¬/MWh\"))\n",
    "\n",
    "# # Plot supplies and demands\n",
    "supplychart = plot(x1, supplyvalues,labels=reshape(supplynames,1,length(supplynames)),title=\"Supply\", ylabel = \"GWh/h\")\n",
    "# demandchart = plot(x1, demandvalues,labels=reshape(demandnames,1,length(demandnames)),title=\"Demand\", ylabel = \"GWh/h\")\n",
    "# supplychart = areaplot(x1, sum(supplyvalues,dims=2),title=\"Supply\", ylabel = \"GWh/h\")\n",
    "# demandchart = areaplot(x1, sum(demandvalues,dims=2),title=\"Demand\", ylabel = \"GWh/h\")\n",
    "# display(plot([supplychart,demandchart]...,layout=(1,2),size=(800,500)))\n",
    "display(plot(supplychart,size=(800,500)))\n",
    "\n",
    "# Plot storages\n",
    "# display(areaplot(x2, hydrolevels1,labels=reshape(hydronames,1,length(hydronames)),size=(800,500),title=\"Reservoir levels\", ylabel = \"TWh\")) #\n",
    "display(areaplot(x2, dropdims(sum(hydrolevels1,dims=2),dims=2),labels=\"Total reservoirs\",size=(800,500),title=\"Reservoir levels\", ylabel = \"TWh\")) #\n",
    "\n",
    "display(areaplot(x1, dropdims(sum(batterylevels,dims=2),dims=2),labels=\"Total batteries\",size=(800,500),title=\"Battery levels\", ylabel = \"GWh\")) #\n",
    "\n",
    "# Plot list of yearly mean production and demand for each supply/demand\n",
    "meandemand = dropdims(mean(demandvalues,dims=1),dims=1)\n",
    "meanproduction = dropdims(mean(supplyvalues,dims=1),dims=1)\n",
    "supplydf = sort(DataFrame(Supplyname = supplynames, Yearly_supply_TWh = meanproduction*8.76),[:Yearly_supply_TWh], rev = true)\n",
    "demanddf = sort(DataFrame(Demandname = demandnames, Yearly_demand_TWh = meandemand*8.76),[:Yearly_demand_TWh], rev = true)\n",
    "supplydf[!,:ID] = collect(1:length(supplynames))\n",
    "demanddf[!,:ID] = collect(1:length(demandnames))\n",
    "joineddf = select!(outerjoin(supplydf,demanddf;on=:ID),Not(:ID))\n",
    "show(joineddf,allcols=true, allrows=true, nosubheader = true)\n",
    "\n",
    "# Check that total supply equals total demand\n",
    "show(combine(joineddf, [:Yearly_supply_TWh, :Yearly_demand_TWh] .=> sumâˆ˜skipmissing), nosubheader = true)\n",
    "\n",
    "# # Plot list of yearly income and cost for each supply/demand (only works if exogenprices are collected)\n",
    "# supplyrev = copy(supplyvalues)\n",
    "# for (i,supplybalancename) in enumerate(supplybalancenames)\n",
    "#     idx = findfirst(isequal(supplybalancename), powerbalancenames)\n",
    "#     supplyrev[:,i] .= supplyrev[:,i] .* prices[:,idx]\n",
    "# end\n",
    "# demandrev = copy(demandvalues)\n",
    "# for (i,demandbalancename) in enumerate(demandbalancenames)\n",
    "#     idx = findfirst(isequal(demandbalancename), powerbalancenames)\n",
    "#     demandrev[:,i] .= demandrev[:,i] .* prices[:,idx]\n",
    "# end\n",
    "# meandemandrev = dropdims(mean(demandrev,dims=1),dims=1)\n",
    "# meanproductionrev = dropdims(mean(supplyrev,dims=1),dims=1)\n",
    "# supplyrevdf = sort(DataFrame(Supplyname = supplynames, Yearly_rev_millâ‚¬ = meanproductionrev*8.76),[:Yearly_rev_millâ‚¬], rev = true)\n",
    "# demandrevdf = sort(DataFrame(Demandname = demandnames, Yearly_cost_millâ‚¬ = meandemandrev*8.76),[:Yearly_cost_millâ‚¬], rev = true)\n",
    "# supplyrevdf[!,:ID] = collect(1:length(supplynames))\n",
    "# demandrevdf[!,:ID] = collect(1:length(demandnames))\n",
    "# joinedrevdf = select!(outerjoin(supplyrevdf,demandrevdf;on=:ID),Not(:ID))\n",
    "# # show(joinedrevdf,allcols=true, allrows=true, nosubheader = true)\n",
    "\n",
    "# # Sum revenues and cost\n",
    "# show(combine(joinedrevdf, [:Yearly_rev_millâ‚¬, :Yearly_cost_millâ‚¬] .=> sumâˆ˜skipmissing), nosubheader = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8846a",
   "metadata": {},
   "source": [
    "- We only show results for NO2 to make the plots more readable\n",
    "- Yearly_supply_TWh and Yearly_demand_TWh is the mean production timed with 8736.\n",
    "- Transmission into the area is added to supply, while transmission out is added to demand.\n",
    "- The reason why the supply does not match the demand is that the filtering does not split up watercourses where hydropower plants are in different areas. The supply side (of NO2) therefore contains 14 hydropower plants in NO1 and NO5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe12697",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "984fd231",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
