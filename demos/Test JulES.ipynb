{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009d8280",
   "metadata": {},
   "source": [
    "# Prototype JulES v1\n",
    "\n",
    "Check out the ReadMe page on Github for a description of JulES. This is a demo of the prototype implementation of JulES in a stepwise manner. Here are some of the most important steps: \n",
    "- Load the TuLiPa and JulES code on parallel processors so that we can run scenarios and subsystems in parallel\n",
    "- Decide on simulation and scenario parameters\n",
    "- First time step in the simulation and initializing\n",
    "    - Load datasets for the European power system/market.\n",
    "    - Initialize and run price prognosis models\n",
    "    - Do scenario modelling for the stochastic subsystem models\n",
    "    - Initialize and run the stochastic subsystem models\n",
    "    - Initialize and run the market clearing problem\n",
    "    - Collect results\n",
    "- Simulate the next time steps\n",
    "    - Run price prognosis models, scenario modelling, stochastic subsystem models, market clearing and collect results for each time step\n",
    "- Postprocess, store and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0bc3e",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "# Pkg.update(\"TuLiPa\") # uncomment to update TuLiPa to latest version\n",
    "# Pkg.develop(path=joinpath(dirname(dirname(pwd())),\"TuLiPa\")); Pkg.status() # go to development version\n",
    "# Pkg.undo(); Pkg.status() # go back to main package version\n",
    "# Pkg.add(url=\"https://github.com/NVE/TuLiPa.git\"); Pkg.status() # alternative go back to latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf4aa8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using DataFrames, Statistics, JSON, Distributed, Clustering, YAML, CSV\n",
    "#plotlyjs(); uncomment for interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = YAML.load_file(joinpath(dirname(dirname(pwd())), \"JulESIO\", \"config_jules_vassdrag.yml\"))\n",
    "scenarioyear = 1981\n",
    "datayear = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = YAML.load_file(joinpath(dirname(dirname(pwd())), \"JulESIO\", \"config_jules_solbatteri.yml\"))\n",
    "# scenarioyear = 1991\n",
    "# datayear = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02815644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = YAML.load_file(joinpath(dirname(dirname(pwd())), \"JulESIO\", \"config_jules_prognose.yml\"))\n",
    "# scenarioyear = 1991\n",
    "# datayear = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = YAML.load_file(joinpath(dirname(dirname(pwd())), \"JulESIO\", \"config_jules_la.yml\"))\n",
    "# scenarioyear = 1981\n",
    "# datayear = 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c3161",
   "metadata": {},
   "source": [
    "### Prepare parallell processing - import code on all cores\n",
    "The problem is simulated on 31 2.20 GHz processors running in parallel. TODO: Test on faster processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "const numcores = config[\"main\"][\"numcores\"]\n",
    "\n",
    "if nprocs() < numcores\n",
    "    addprocs(numcores - nprocs())\n",
    "end\n",
    "\n",
    "@show nprocs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using TuLiPa, Dates\n",
    "# @everywhere include(joinpath(dirname(dirname(dirname(pwd()))),\"jgrc/TuLiPa/src/TuLiPa.jl\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2448075",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere include(joinpath(dirname(pwd()),\"src/JulES.jl\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35482c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "function getdataset(config, scenarioyear)\n",
    "    settings = config[config[\"main\"][\"settings\"]]\n",
    "\n",
    "    method = config[\"main\"][\"function\"]\n",
    "    if method == \"nve_prognosis\"\n",
    "        sti_dataset = joinpath(config[\"main\"][\"input\"], \"static_input\")\n",
    "        weekstart = config[\"main\"][\"weekstart\"]\n",
    "\n",
    "        sti_dataset1 = joinpath(config[\"main\"][\"input\"], \"Uke_$weekstart\", \"input\")\n",
    "\n",
    "        exd = JSON.parsefile(joinpath(sti_dataset1, \"exogenprices_prognose1.json\"))\n",
    "        exogen = JulES.getelements(exd, sti_dataset1)\n",
    "\n",
    "        add = JSON.parsefile(joinpath(sti_dataset, \"aggdetd2.json\"))\n",
    "        aggdetd = JulES.getelements(add, sti_dataset)\n",
    "\n",
    "        ipad = JSON.parsefile(joinpath(sti_dataset1, \"tilsigsprognoseragg$scenarioyear.json\"))\n",
    "        agginflow = JulES.getelements(ipad, sti_dataset1)\n",
    "\n",
    "        thd = JSON.parsefile(joinpath(sti_dataset, \"termisk1.json\"))\n",
    "        thermal = JulES.getelements(thd, sti_dataset)\n",
    "\n",
    "        wsd = JSON.parsefile(joinpath(sti_dataset, \"vindsol.json\"))\n",
    "        windsol = JulES.getelements(wsd, sti_dataset)\n",
    "\n",
    "        trd = JSON.parsefile(joinpath(sti_dataset1, \"nett.json\"))\n",
    "        transm = JulES.getelements(trd)\n",
    "\n",
    "        cod = JSON.parsefile(joinpath(sti_dataset, \"forbruk5.json\"))\n",
    "        cons = JulES.getelements(cod, sti_dataset)\n",
    "\n",
    "        fpd = JSON.parsefile(joinpath(sti_dataset1, \"brenselspriser.json\"))\n",
    "        fuel = JulES.getelements(fpd, sti_dataset1)\n",
    "\n",
    "        nud = JSON.parsefile(joinpath(sti_dataset1, \"nuclear.json\"))\n",
    "        nuclear = JulES.getelements(nud, sti_dataset1)\n",
    "\n",
    "        dse = JSON.parsefile(joinpath(sti_dataset, \"tidsserier_detd.json\"))\n",
    "        detdseries = JulES.getelements(dse, sti_dataset)\n",
    "\n",
    "        dda = JSON.parsefile(joinpath(sti_dataset, \"dataset_detd.json\"))\n",
    "        detdstructure = JulES.getelements(dda)\n",
    "\n",
    "        ipd = JSON.parsefile(joinpath(sti_dataset1, \"tilsigsprognoser$scenarioyear.json\"))\n",
    "        inflow = JulES.getelements(ipd, sti_dataset1)\n",
    "\n",
    "        progelements = vcat(exogen, aggdetd, thermal, windsol, transm, cons, agginflow, fuel, nuclear)\n",
    "        aggstartmagdict = JSON.parsefile(joinpath(sti_dataset1, \"aggstartmagdict.json\"), dicttype=Dict{String, Float64})\n",
    "\n",
    "        if settings[\"problems\"][\"onlyagghydro\"]\n",
    "            global detailedelements = elements\n",
    "            global startmagdict = Dict()\n",
    "            global detailedrescopl = Dict()\n",
    "            return Dict(\"elements\" => progelements, \"startmagdict\" => startmagdict, \"aggstartmagdict\" => aggstartmagdict, \"detailedrescopl\" => detailedrescopl)\n",
    "        else\n",
    "            global elements = vcat(exogen, detdseries, detdstructure, thermal, windsol, transm, cons, inflow, fuel, nuclear)\n",
    "            global startmagdict = JSON.parsefile(joinpath(sti_dataset1, \"startmagdict.json\"))\n",
    "            global detailedrescopl = JSON.parsefile(joinpath(sti_dataset, \"magasin_elspot.json\")\n",
    "            return Dict(\"elements\" => elements, \"progelements\" => progelements, \"startmagdict\" => startmagdict, \"aggstartmagdict\" => aggstartmagdict, \"detailedrescopl\" => detailedrescopl))\n",
    "        end\n",
    "    elseif method == \"nve_la\"\n",
    "        sti_thema = joinpath(config[\"main\"][\"input\"], \"datasett\", \"data_fra_thema\")\n",
    "        sti_vannkraft = joinpath(config[\"main\"][\"input\"], \"datasett\", \"data_fra_dynmodell\")\n",
    "\n",
    "        tsd = JSON.parsefile(joinpath(sti_thema, \"dataset_thema.json\"))\n",
    "        themastructure = JulES.getelements(tsd, sti_thema)\n",
    "        tst = JSON.parsefile(joinpath(sti_thema, \"dataset_thema_excl_hydro_nose.json\"))\n",
    "        themastructure_exl = JulES.getelements(tst, sti_thema)\n",
    "        tse = JSON.parsefile(joinpath(sti_thema, \"tidsserier_thema.json\"))\n",
    "        themaseries = JulES.getelements(tse, sti_thema)\n",
    "\n",
    "        dse = JSON.parsefile(joinpath(sti_vannkraft, \"tidsserier_detd.json\"))\n",
    "        detdseries = JulES.getelements(dse)\n",
    "        dst = JSON.parsefile(joinpath(sti_vannkraft, \"dataset_detd.json\"))\n",
    "        detdstructure = JulES.getelements(dst)\n",
    "\n",
    "        progelements = vcat(themaseries, themastructure)\n",
    "        \n",
    "        if settings[\"problems\"][\"onlyagghydro\"]\n",
    "            global detailedrescopl = Dict()\n",
    "            return Dict(\"elements\" => progelements, \"detailedrescopl\" => detailedrescopl)\n",
    "        else\n",
    "            global elements = vcat(themaseries, themastructure_exl, detdseries, detdstructure)\n",
    "            global detailedrescopl = JSON.parsefile(joinpath(sti_vannkraft, \"magasin_elspot.json\"))\n",
    "            return Dict(\"elements\" => elements, \"progelements\" => progelements, \"detailedrescopl\" => detailedrescopl)\n",
    "        end\n",
    "    elseif method == \"nve_solbatteri\"\n",
    "        elements = DataElement[]\n",
    "\n",
    "        # Solar, battery and transmission parameters\n",
    "        transmcap = config[\"data\"][\"transmcap\"] # MW\n",
    "        transmeff = config[\"data\"][\"transmeff\"] # Small loss to avoid unnecessary transfers\n",
    "        storagecap = config[\"data\"][\"storagecap\"] # GWh\n",
    "        chargecap = config[\"data\"][\"chargecap\"]# MW\n",
    "        lossbattery = config[\"data\"][\"lossbattery\"] # the whole loss when the battery charges\n",
    "        solarcap = config[\"data\"][\"solarcap\"] # MW\n",
    "\n",
    "        # Power balances for price areas and transmission\n",
    "        addexogenbalance!(elements, \"PowerBalance_ExternalHub\", \"Power\", \"AreaPrice\")\n",
    "        price_path = joinpath(config[\"main\"][\"input\"], config[\"data\"][\"price\"])\n",
    "        df = CSV.read(price_path, DataFrame; header=3, decimal=',', types=Float64)\n",
    "        df[:,\"aar\"] = cld.(1:first(size(df)), 2912) .+ 1957\n",
    "        df[:,\"tsnitt\"] = rem.(0:(first(size(df))-1), 2912) .+ 1\n",
    "        df.datetime .= getisoyearstart.(Int.(df.aar)) + Hour.((df.tsnitt.-1)*3) # TODO: Include week 53. Now ignored and flat prices.\n",
    "        push!(elements, DataElement(TIMEINDEX_CONCEPT,\"VectorTimeIndex\",\"AreaPriceProfileIndex\",\n",
    "                Dict(\"Vector\" => df.datetime)))\n",
    "        push!(elements, DataElement(TIMEVALUES_CONCEPT,\"VectorTimeValues\",\"AreaPriceProfileValues\",\n",
    "                Dict(\"Vector\" => df[:,\"Vestsyd\"].*1000))) # *1000 to go from €/MWh to €/GWh\n",
    "        push!(elements, getelement(TIMEVECTOR_CONCEPT,\"RotatingTimeVector\",\"AreaProfile\",\n",
    "                (TIMEINDEX_CONCEPT,\"AreaPriceProfileIndex\"),(TIMEVALUES_CONCEPT,\"AreaPriceProfileValues\")))\n",
    "        addparam!(elements, \"MeanSeriesParam\", \"AreaPrice\", 1.0, \"AreaProfile\")\n",
    "\n",
    "        addbalance!(elements, \"PowerBalance_HomeHub\", \"Power\")\n",
    "\n",
    "        addpowertrans!(elements, \"PowerBalance_ExternalHub\", \"PowerBalance_HomeHub\", transmcap, transmeff)\n",
    "        addpowertrans!(elements, \"PowerBalance_HomeHub\", \"PowerBalance_ExternalHub\", transmcap, transmeff)\n",
    "\n",
    "        # Add battery\n",
    "        addbattery!(elements, \"Battery\", \"PowerBalance_HomeHub\", storagecap, lossbattery, chargecap)\n",
    "\n",
    "        # Add solar production as an RHSTerm\n",
    "        solar_path = joinpath(config[\"main\"][\"input\"], config[\"data\"][\"solar\"]) # profiles from https://www.nve.no/energi/analyser-og-statistikk/vaerdatasett-for-kraftsystemmodellene/\n",
    "        df = CSV.read(solar_path, DataFrame)\n",
    "        dfmt = DateFormat(\"yyyy-mm-dd HH:MM:SS\")\n",
    "        df.Timestamp = DateTime.(df.Timestamp, dfmt)\n",
    "        @assert issorted(df.Timestamp)\n",
    "        start = first(df.Timestamp)\n",
    "        numperiods = length(df.Timestamp)\n",
    "        push!(elements, DataElement(TIMEINDEX_CONCEPT, \"RangeTimeIndex\", \"SolProfileTimeIndex\", \n",
    "                Dict(\"Start\" => start, \"Delta\" => Hour(1), \"Steps\" => numperiods)))\n",
    "        push!(elements, DataElement(TIMEVALUES_CONCEPT, \"VectorTimeValues\", \"SolProfilValues\",\n",
    "                Dict(\"Vector\" => df.SolarGER)))\n",
    "        push!(elements, DataElement(TIMEVECTOR_CONCEPT, \"RotatingTimeVector\", \"SolProfil\",\n",
    "                Dict(TIMEVALUES_CONCEPT => \"SolProfilValues\", TIMEINDEX_CONCEPT => \"SolProfileTimeIndex\")))\n",
    "        push!(elements, DataElement(PARAM_CONCEPT, \"MWToGWhSeriesParam\", \"SolParam\", Dict(\"Level\" => solarcap, \"Profile\" => \"SolProfil\")))\n",
    "        addrhsterm!(elements, \"SolParam\", \"PowerBalance_HomeHub\", DIRECTIONIN)\n",
    "\n",
    "        return Dict(\"elements\" => elements, \"detailedrescopl\" => Dict())\n",
    "    elseif method == \"nve_vassdrag\"\n",
    "        # Read watercourse, elspot area and price series\n",
    "        watercourse = config[\"data\"][\"watercourse\"]\n",
    "        elspotnames = config[\"data\"][\"elspotnames\"] # some watercourses are in several elspot areas\n",
    "        priceseriesname = config[\"data\"][\"priceseriesname\"] \n",
    "\n",
    "        # Read hydropower dataelements from json-files\n",
    "        sti_dynmodelldata = joinpath(config[\"main\"][\"input\"], \"dataset_vassdrag\")\n",
    "        tidsserie = JSON.parsefile(joinpath(sti_dynmodelldata,\"tidsserier_detd.json\"))\n",
    "        detdseries = getelements(tidsserie, sti_dynmodelldata);\n",
    "        dst = JSON.parsefile(joinpath(sti_dynmodelldata, \"dataset_detd_\" * watercourse * \".json\"))\n",
    "        detdstructure = getelements(dst);\n",
    "        elements = vcat(detdseries,detdstructure)\n",
    "\n",
    "        # Add an exogenous price area that the plants and pumps can interact with. All units are in NO5.\n",
    "        for elspotname in elspotnames\n",
    "            addexogenbalance!(elements, \"PowerBalance_\" * elspotname, \"Power\", \"AreaPrice\")\n",
    "        end\n",
    "\n",
    "        # Add dataelements for price in exogen area\n",
    "        price_path = joinpath(config[\"main\"][\"input\"], config[\"data\"][\"price\"])\n",
    "        df = CSV.read(price_path, DataFrame; header=3, decimal=',', types=Float64)\n",
    "        df[:,\"aar\"] = cld.(1:first(size(df)), 2912) .+ 1957\n",
    "        df[:,\"tsnitt\"] = rem.(0:(first(size(df))-1), 2912) .+ 1\n",
    "        df.datetime .= getisoyearstart.(Int.(df.aar)) + Hour.((df.tsnitt.-1)*3) # TODO: Include week 53. Now ignored and flat prices.\n",
    "        push!(elements, DataElement(TIMEINDEX_CONCEPT,\"VectorTimeIndex\",\"AreaPriceProfileIndex\",\n",
    "                Dict(\"Vector\" => df.datetime)))\n",
    "        push!(elements, DataElement(TIMEVALUES_CONCEPT,\"VectorTimeValues\",\"AreaPriceProfileValues\",\n",
    "                Dict(\"Vector\" => df[:,priceseriesname])))\n",
    "        push!(elements, getelement(TIMEVECTOR_CONCEPT,\"RotatingTimeVector\",\"AreaProfile\",\n",
    "                (TIMEINDEX_CONCEPT,\"AreaPriceProfileIndex\"),(TIMEVALUES_CONCEPT,\"AreaPriceProfileValues\")))\n",
    "        addparam!(elements, \"MeanSeriesIgnorePhaseinParam\", \"AreaPrice\", 1.0, \"AreaProfile\")\n",
    "\n",
    "        return Dict(\"elements\" => elements, \"detailedrescopl\" => Dict())\n",
    "    else\n",
    "        error(\"$method not supported\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ea002",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = getdataset(config, scenarioyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = JulES.run_serial(config, datayear, scenarioyear, dataset)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
